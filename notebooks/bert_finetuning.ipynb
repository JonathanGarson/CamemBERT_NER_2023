{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of BERT for NER task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import Dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fe3980f17248ebba13cfca8c0e4739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "model_checkpoint = \"Jean-Baptiste/camembert-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\") #this last argument might be a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForTokenClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# This will print the device (either 'cuda' or 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# You can then move your model and data to this device like this:\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_conll(path:str):\n",
    "    # Initialize a list to store the data\n",
    "    conll_data = []\n",
    "\n",
    "    # Open the CoNLL file in read mode\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        conll_data = file.read()\n",
    "        # Read each line in the file\n",
    "\n",
    "    # Split the data into sentences\n",
    "    sentences = conll_data.strip().split('\\n\\n')\n",
    "\n",
    "    # Initialize empty lists to store text and labels\n",
    "    text_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Process each sentence\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split('\\n')\n",
    "        text = \" \".join(token.split()[0] for token in tokens)\n",
    "        labels = \" \".join(token.split()[-1] for token in tokens)\n",
    "        text_list.append(text)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame({'text': text_list, 'label': labels_list})\n",
    "\n",
    "    return df\n",
    "\n",
    "#we divide the data into train, test, and validation sets\n",
    "\n",
    "def split_data(data_dict, train_size=0.8, test_size=0.1, val_size=0.1, random_seed=None):\n",
    "    # Set a random seed for reproducibility\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Combine input_ids, attention_mask, and aligned_labels into a single list\n",
    "    combined_data = list(zip(data_dict['input_ids'], data_dict['attention_mask'], data_dict['labels']))\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.shuffle(combined_data)\n",
    "\n",
    "    # Calculate the sizes of each set\n",
    "    total_size = len(combined_data)\n",
    "    train_size = int(train_size * total_size)\n",
    "    test_size = int(test_size * total_size)\n",
    "    val_size = int(val_size * total_size)\n",
    "\n",
    "    # Split the data into train, test, and val sets\n",
    "    train_data = combined_data[:train_size]\n",
    "    test_data = combined_data[train_size:train_size + test_size]\n",
    "    val_data = combined_data[train_size + test_size:train_size + test_size + val_size]\n",
    "\n",
    "    # Unzip the data to restore the original structure\n",
    "    train_input_ids, train_attention_mask, train_aligned_labels = zip(*train_data)\n",
    "    test_input_ids, test_attention_mask, test_aligned_labels = zip(*test_data)\n",
    "    val_input_ids, val_attention_mask, val_aligned_labels = zip(*val_data)\n",
    "\n",
    "    # Create dictionaries for the train, test, and val sets\n",
    "    train_set = {\n",
    "        'input_ids': list(train_input_ids),\n",
    "        'attention_mask': list(train_attention_mask),\n",
    "        'labels': list(train_aligned_labels)\n",
    "    }\n",
    "    test_set = {\n",
    "        'input_ids': list(test_input_ids),\n",
    "        'attention_mask': list(test_attention_mask),\n",
    "        'labels': list(test_aligned_labels)\n",
    "    }\n",
    "    val_set = {\n",
    "        'input_ids': list(val_input_ids),\n",
    "        'attention_mask': list(val_attention_mask),\n",
    "        'labels': list(val_aligned_labels)\n",
    "    }\n",
    "\n",
    "    return train_set, test_set, val_set\n",
    "\n",
    "def turn_sentence_to_list(sentence):\n",
    "    \"\"\"\n",
    "    Turn a sentence into a list of words\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to tokenize\n",
    "\n",
    "    Returns:\n",
    "        list: list of words\n",
    "    \"\"\"\n",
    "    return sentence.split()\n",
    "\n",
    "def format_text(df):\n",
    "    formated_text = []\n",
    "\n",
    "    text = df[\"text\"]\n",
    "    for i in text:\n",
    "        i = turn_sentence_to_list(i)\n",
    "        formated_text.append(i)\n",
    "\n",
    "    # we add it to the dataframe\n",
    "    df[\"formated_text\"] = formated_text\n",
    "    return df\n",
    "\n",
    "def format_labels(df):\n",
    "    labels = df[\"label\"].tolist()\n",
    "\n",
    "    formated_labels = []\n",
    "\n",
    "    for label in labels:\n",
    "        # label = list_to_string(label)\n",
    "        label = turn_sentence_to_list(label)\n",
    "        formated_labels.append(label)\n",
    "        # print(label)\n",
    "\n",
    "    # we add it to the dataframe\n",
    "\n",
    "    df[\"formated_labels\"] = formated_labels\n",
    "    return df\n",
    "\n",
    "def change_ids(list_ids:list, new_id:dict):\n",
    "    \"\"\"\n",
    "    change the ids of a list of ids to a new id\n",
    "\n",
    "    Args:\n",
    "        list_ids (list): list of ids\n",
    "        new_id (dict): dictionary with the new id\n",
    "    \"\"\"\n",
    "    return [new_id.get(id) for id in list_ids]\n",
    "\n",
    "def align_labels(word_ids:list, tag_list:list):\n",
    "    \"\"\"\n",
    "    Align the labels with the words\n",
    "\n",
    "    Args:\n",
    "        word_ids (list): list of ids of the words\n",
    "        tag_list (list): list of tags\n",
    "    \"\"\"\n",
    "    aligned_labels = []\n",
    "    for i in word_ids:\n",
    "        if i is None:\n",
    "            aligned_labels.append(-100)\n",
    "        else:\n",
    "            aligned_labels.append(tag_list[i])\n",
    "    return aligned_labels\n",
    "\n",
    "def check_labels(list_labels:list):\n",
    "    for label in list_labels:\n",
    "        if type(label)!=int:\n",
    "            print(label)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def count_error(df, column:str):\n",
    "    \"\"\"\n",
    "    Count the number of errors - a cell containing a non numerical value - in a column of a dataframe\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): dataframe to check\n",
    "        column (str): column to check\n",
    "\n",
    "    Returns:\n",
    "        int: number of errors\n",
    "    \"\"\"\n",
    "    return len(df[column])- sum(df[column].apply(lambda x: check_labels(x)))\n",
    "\n",
    "def create_iids_am(df):\n",
    "    \"\"\"\n",
    "    Create the input ids and attention mask columns\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe containing the data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe containing the data with the input ids and attention mask columns\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for _,i in df.iterrows():\n",
    "        input = i[\"ids\"][\"input_ids\"]\n",
    "        attention = i[\"ids\"][\"attention_mask\"]\n",
    "\n",
    "        input_ids.append(input)\n",
    "        attention_mask.append(attention)\n",
    "\n",
    "    df[\"input_ids\"] = input_ids\n",
    "    df[\"attention_mask\"] = attention_mask\n",
    "    return df\n",
    "\n",
    "def select_columns(df, columns:list):\n",
    "    \"\"\"\n",
    "    Select columns from a dataframe\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe\n",
    "        columns (list): list of columns to select\n",
    "\n",
    "    \"\"\"\n",
    "    df = df[columns].copy()\n",
    "    return df\n",
    "\n",
    "def tokenize_and_align_data(path_conll:str, new_id:dict):\n",
    "    \"\"\"\n",
    "    Tokenize the text and align the labels\n",
    "\n",
    "    Args:\n",
    "        path_conll (str): path to the conll file\n",
    "        new_id (dict): dictionary with the new id\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe containing the data\n",
    "    \"\"\"\n",
    "    #charge and create the df\n",
    "    df = charge_conll(path_conll)\n",
    "    df = format_text(df)\n",
    "    df = format_labels(df)\n",
    "    df[\"new_labels\"]=df[\"label\"].apply(lambda x: change_ids(x.split(\" \"), new_id))\n",
    "\n",
    "    #tokenize and align the text\n",
    "    df[\"ids\"] = df[\"formated_text\"].apply(lambda x: tokenizer(x, truncation=True, is_split_into_words=True))\n",
    "    df = create_iids_am(df)\n",
    "    df[\"word_ids\"] = df[\"formated_text\"].apply(lambda x: tokenizer(x, truncation=True, is_split_into_words=True).word_ids())\n",
    "    df[\"aligned_labels\"] = df.apply(lambda x: align_labels(x[\"word_ids\"], x[\"new_labels\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "def apply_tokenization(conll_path:str, new_id:dict, columns:list, new_names:dict, save_path=False, output_save_csv=None):\n",
    "    \"\"\"\n",
    "    This function apply the tokenization and alignment to a conll file and select the columns we want to keep\n",
    "\n",
    "    Args:\n",
    "        conll_path (str): path to the conll file\n",
    "        new_id (dict): dictionary with the new id\n",
    "        columns (list): list of columns to keep\n",
    "        new_names (dict): dictionary with the new names of the columns\n",
    "        save_path (bool, optional): if True, save the dataframe in a csv file. Defaults to False.\n",
    "        output_save_csv ([type], optional): path to the csv file. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe containing the data\n",
    "    \"\"\"\n",
    "    df = tokenize_and_align_data(conll_path, new_id=new_id)\n",
    "    df = select_columns(df, columns)\n",
    "    df = df.rename(columns=new_names)\n",
    "    #we check the length of the two columns so that they are of the same dimensions\n",
    "    print(f\"nombre de 'aligned_labels' faux: {count_error(df, 'aligned_labels')}\")\n",
    "    if save_path:\n",
    "        df.to_csv(output_save_csv, index=False)\n",
    "    return df\n",
    "\n",
    "def final_formating(df, start:int, end:int):\n",
    "    \"\"\"\n",
    "    Collect the data from a dataframe in a list for a given range of sentences and store them into a dictionnary\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe containing the data\n",
    "        start (int): index of the first sentence to collect\n",
    "        end (int): index of the last sentence to collect\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionnary containing the data\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(start, end):\n",
    "        input_ids.append(df[\"input_ids\"][i])\n",
    "        attention_mask.append(df[\"attention_mask\"][i])\n",
    "        labels.append(df[\"aligned_labels\"][i])\n",
    "\n",
    "    data = {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n",
    "    return data\n",
    "\n",
    "def download_and_treat_data(conll_path:str, new_id:dict, columns:list, new_names:dict, start:int, end:int, csv=False, output_save=None):\n",
    "    \"\"\"\n",
    "    This function compile all the previous one and treat automatically all data provided as conll format.\\n\n",
    "    The objective is to provide a dictionnary containing the data for a given range of sentences with only one function. \\n\n",
    "    The same results can be obtained by parts with apply_tokenization and final_formating functions. This one is more a convenience function.\\n\n",
    "    It is also possible to obtain a csv file if csv is set to True and a path is provided in output_save.\n",
    "\n",
    "    Args:\n",
    "        conll_path (str): path to the conll file\n",
    "        new_id (dict): dictionnary to change the labels\n",
    "        columns (list): columns to keep\n",
    "        new_names (dict): new names of the columns\n",
    "        start (int): index of the first sentence to collect\n",
    "        end (int): index of the last sentence to collect\n",
    "    \n",
    "    Returns:\n",
    "        dict: dictionnary containing the data\n",
    "    \"\"\"\n",
    "    df = apply_tokenization(conll_path, new_id=new_id, columns=columns, new_names=new_names)\n",
    "\n",
    "    if csv:\n",
    "        df.to_csv(output_save, index=False)\n",
    "\n",
    "    data = final_formating(df, start, end)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de 'aligned_labels' faux: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at Jean-Baptiste/camembert-ner and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([31]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([31, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "new_id = {\"O\":0,\"B-SYND\":1, \"I-SYND\":1, \"SYND\":1, \"B-DIR\":2, \"I-DIR\":2, \"DIR\":2, \"B-DATE\":4, \"I-DATE\":4, \"DATE\":4, \"B-ENT\":3, \"I-ENT\":3, \"ENT\":3, \"B-CAD\":5, \"I-CAD\":5, \"CAD\":5, \"B-INT\":6, \"I-INT\":6, \"INT\":6,\"B-OUV\":7, \"I-OUV\":7, \"OUV\":7, \"B-NCAD\":8, \"I-NCAD\":8, \"NCAD\":8,\"B-NOUV\":9, \"I-NOUV\":9, \"NOUV\":9, \"B-TOUS\":10,\"I-TOUS\":10, \"TOUS\":10, \"B-AG CAD\":11,\"I-AG CAD\":11, \"AG CAD\":11, \"B-AG INT\":12, \"I-AG INT\":12, \"AG INT\":12, \"B-AG OUV\":13, \"I-AG OUV\":13, \"AG OUV\":13,\"B-AG NCAD\":14, \"I-AG NCAD\":14, \"AG NCAD\":14, \"B-AG NOUV\":15, \"I-AG NOUV\":15, \"AG NOUV\":15,\"B-AI CAD\":16, \"I-AI CAD\":16,\"AI CAD\":16,\"B-AI INT\":17, \"I-AI INT\":17, \"AI INT\":17,\"B-AI OUV\":18, \"I-AI OUV\":18,\"AI OUV\":18,\"B-AI NCAD\":19, \"I-AI NCAD\":19,\"AI NCAD\":19,\"B-AI NOUV\":20, \"I-AI NOUV\":20, \"AI NOUV\":20, \"B-AG\":21, \"I-AG\":21, \"AG\":21,\"B-AI\":22, \"I-AI\":22,\"AI\":22,\"B-ATOT\":23,\"I-ATOT\":23, \"ATOT\":23,\"B-ATOT CAD\":24, \"I-ATOT CAD\":24, \"ATOT CAD\":24,\"B-ATOT INT\":25, \"I-ATOT INT\":25,\"ATOT INT\":25,\"B-ATOT OUV\":26, \"I-ATOT OUV\":26, \"ATOT OUV\":26,\"B-ATOT NCAD\":27, \"I-ATOT NCAD\":27, \"ATOT NCAD\":27,\"B-ATOT NOUV\":28, \"I-ATOT NOUV\":28, \"ATOT NOUV\":28,\"B-PPV\":29, \"I-PPV\":29, \"PPV\":29,\"B-PPVm\":30, \"I-PPVm\":30, \"PPVm\":30}\n",
    "columns = [\"formated_text\", \"formated_labels\",\"new_labels\",\"word_ids\", \"input_ids\", \"attention_mask\", \"aligned_labels\"]\n",
    "new_names = {\"formated_text\": \"text\", \"new_labels\": \"label\", \"word_ids\": \"word_ids\", \"aligned_labels\": \"aligned_labels\"}\n",
    "conll_path = r\"../data/raw/data449.conll\"\n",
    "start = 0\n",
    "end = 449\n",
    "output_save = r\"../data/intermediate/data449_token.csv\"\n",
    "\n",
    "data = download_and_treat_data(conll_path=conll_path, new_id=new_id, columns=columns, new_names=new_names, start=start, end=end, csv=True, output_save=output_save)\n",
    "\n",
    "train_data, test_data, val_data = split_data(data)\n",
    "\n",
    "# Create a Dataset object\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "# Create a list of labels\n",
    "reverse_id = {v: k for k, v in new_id.items()}\n",
    "second_elements = [value for value in reverse_id.values()]\n",
    "label_list = second_elements\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_checkpoint = \"Jean-Baptiste/camembert-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\", num_labels=len(label_list), ignore_mismatched_sizes=True) #this last argument might be a mistake\n",
    "\n",
    "# import data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors='pt')\n",
    "\n",
    "# Dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83262c0a6f2422eb3131e269e0ef97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# training arguments\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "# metric used for evaluation\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "# We want to do a metrics function to compute the accuracy of the model\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 02:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.494638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.143358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.093585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PPV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PPVm seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DATE seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AI seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYND seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ENT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NCAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: TOUS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OUV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ATOT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/mamba/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=135, training_loss=1.6286810980902777, metrics={'train_runtime': 179.8047, 'train_samples_per_second': 5.99, 'train_steps_per_second': 0.751, 'total_flos': 281155516598112.0, 'train_loss': 1.6286810980902777, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
