{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of BERT for NER task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import Dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_conll_data(path:str):\n",
    "    \"\"\"\n",
    "    Import conll_data and convert it to dataset format while preserving full labels.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        conll_data = file.read()\n",
    "\n",
    "    sentences = conll_data.strip().split('\\n\\n')\n",
    "\n",
    "    # Initialize empty lists to store text and labels\n",
    "    text_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Process each sentence\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split('\\n')\n",
    "        text_tokens = [token.split()[0] for token in tokens]\n",
    "        label_tokens = []\n",
    "\n",
    "        for token in tokens:\n",
    "            token_parts = token.split()\n",
    "            if len(token_parts) > 4:\n",
    "                label = \" \".join(token_parts[-2:])  # Take the last two elements\n",
    "            else:\n",
    "                label = token_parts[-1]  # Take the last element\n",
    "            label_tokens.append(label)\n",
    "\n",
    "        text_list.append(text_tokens)\n",
    "        labels_list.append(label_tokens)\n",
    "\n",
    "    data = {\"text\": text_list, \"labels\": labels_list}\n",
    "\n",
    "    return data\n",
    "\n",
    "def turn_to_dataset(data:dict):\n",
    "    \"\"\"\n",
    "    It turn dictionnary of conll into Dataset object of the datasets library from Huggingface\n",
    "    \"\"\"\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "def to_numeric_labels(list_ids, new_id):\n",
    "    \"\"\"\n",
    "    Change the ids of a list of ids to new ids.\n",
    "\n",
    "    Args:\n",
    "        list_ids (list): List of ids.\n",
    "        new_id (dict): Dictionary with the new id mappings.\n",
    "    \"\"\"\n",
    "    return [new_id.get(id) for id in list_ids]\n",
    "\n",
    "def generate_data_format(data, full_dataframe=False, label_list=None, numeric_labels=None, save_to_csv=False, output_path_csv=None):\n",
    "    \"\"\"\n",
    "    This function generates a DataFrame out of the data dictionary/dataset containing the CoNLL information.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Data dictionary containing \"text\" and \"labels\" keys.\n",
    "        full_dataframe (bool): If True, add a \"numeric labels\" column to the DataFrame.\n",
    "        label_list (list): List of labels.\n",
    "        numeric_labels (dict): Dictionary with label to numeric mappings.\n",
    "        save_to_csv (bool): If True, save the DataFrame to a CSV file.\n",
    "        output_path_csv (str): Output path for the CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The generated DataFrame.\n",
    "        dataset : a dataset object of the generated DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    if full_dataframe and label_list is not None and numeric_labels is not None:\n",
    "        df[\"numeric labels\"] = df[\"labels\"].apply(lambda labels: to_numeric_labels(labels, numeric_labels))\n",
    "\n",
    "    dataset = turn_to_dataset(df)\n",
    "    \n",
    "    if save_to_csv:\n",
    "        df.to_csv(output_path_csv, index=False)\n",
    "    \n",
    "    return df, dataset\n",
    "\n",
    "def split_dataset(dataset, test_size=0.2, val_size=0.1, random_seed=None):\n",
    "    \"\"\"\n",
    "    Split a dataset into train, test, and validation subsets.\n",
    "\n",
    "    Args:\n",
    "        dataset (datasets.Dataset): The dataset object from Hugging Face.\n",
    "        test_size (float): The proportion of the dataset to include in the test split (default is 0.2).\n",
    "        val_size (float): The proportion of the dataset to include in the validation split (default is 0.1).\n",
    "        random_seed (int): The random seed for shuffling (optional).\n",
    "\n",
    "    Returns:\n",
    "        datasets.Dataset: Train, test, and validation datasets.\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        dataset = dataset.shuffle(seed=random_seed)\n",
    "\n",
    "    total_size = len(dataset)\n",
    "    test_size = int(total_size * test_size)\n",
    "    val_size = int(total_size * val_size)\n",
    "    train_size = total_size - test_size - val_size\n",
    "\n",
    "    train_data = dataset[:train_size]\n",
    "    test_data = dataset[train_size:train_size + test_size]\n",
    "    val_data = dataset[train_size + test_size:]\n",
    "\n",
    "    return train_data, test_data, val_data\n",
    "\n",
    "def tokenize_and_align(dataset, label_all_tokens=False):\n",
    "    tokenized_inputs = tokenizer(dataset[\"text\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(dataset[\"numeric labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m numeric_label_list \u001b[38;5;241m=\u001b[39m[label_to_numeric[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m word_label_list]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# turn them to dataset object\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m turn_to_dataset(\u001b[43mtrain_data\u001b[49m)\n\u001b[1;32m     31\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m turn_to_dataset(test_data)\n\u001b[1;32m     32\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m turn_to_dataset(val_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# We load the data\n",
    "data = import_conll_data(r\"../data/raw/data449.conll\")\n",
    "\n",
    "# We turn them into a dataset object (from datasets library of Huggingface)\n",
    "dataset = turn_to_dataset(data)\n",
    "\n",
    "# we define a numeric and word list of labels\n",
    "# word_label_list\n",
    "non_ordered_word_label_set = set(label for labels in dataset[\"labels\"] for label in labels)\n",
    "non_ordered_word_label_list = list(non_ordered_word_label_set)\n",
    "word_label_list = [\n",
    "    \"O\", \"B-SYND\", \"I-SYND\", \"B-DIR\", \"I-DIR\", \"B-DATE\", \"I-DATE\", \"B-ENT\", \"I-ENT\", \"B-CAD\", \"I-CAD\", \"B-INT\", \"I-INT\", \"B-OUV\", \"I-OUV\", \"B-NCAD\", \"I-NCAD\", \"B-NOUV\", \"I-NOUV\", \"B-TOUS\", \"I-TOUS\", \n",
    "    \"B-AG CAD\", \"I-AG CAD\", \"B-AG INT\", \"I-AG INT\", \"B-AG OUV\", \"I-AG OUV\", \"B-NCAD AG\", \"I-NCAD AG\", \"B-NOUV AG\", \"I-NOUV AG\", \"B-AI CAD\", \"I-AI CAD\", \"B-AI INT\", \"I-AI INT\", \"B-AI OUV\", \"I-AI OUV\",\n",
    "    \"B-NCAD AI\",\"I-NCAD AI\", \"B-NOUV AI\", \"I-NOUV AI\", \"B-AG\", \"I-AG\", \"B-AI\", \"I-AI\", \"B-ATOT\", \"I-ATOT\", \"B-ATOT CAD\", \"I-ATOT CAD\", \"B-ATOT INT\", \"I-ATOT INT\", \"B-ATOT OUV\", \"I-ATOT OUV\", \n",
    "    \"B-NCAD ATOT\",\"I-NCAD ATOT\", \"B-NOUV ATOT\", \"I-NOUV ATOT\", \"B-PPV\", \"I-PPV\", \"B-PPVm\", \"I-PPVm\"\n",
    "] # I manually ordered them, note that 'ATOT OUV' level seems to be missing in comparison with the \n",
    "\n",
    "# numeric_label_list\n",
    "label_to_numeric = {\n",
    "    \"O\": 0, \"B-SYND\": 1, \"I-SYND\": 2, \"B-DIR\": 3, \"I-DIR\": 4, \"B-DATE\": 5, \"I-DATE\": 6, \"B-ENT\": 7, \"I-ENT\": 8, \"B-CAD\": 9, \"I-CAD\": 10, \"B-INT\": 11, \"I-INT\": 12, \"B-OUV\": 13, \n",
    "    \"I-OUV\": 14, \"B-NCAD\": 15, \"I-NCAD\": 16, \"B-NOUV\": 17, \"I-NOUV\": 18, \"B-TOUS\": 19, \"I-TOUS\": 20, \"B-AG CAD\": 21, \"I-AG CAD\": 22, \"B-AG INT\": 23, \"I-AG INT\": 24, \"B-AG OUV\": 25, \"I-AG OUV\": 26,\n",
    "    \"B-NCAD AG\": 27, \"I-NCAD AG\": 28, \"B-NOUV AG\": 29, \"I-NOUV AG\": 30, \"B-AI CAD\": 31, \"I-AI CAD\": 32, \"B-AI INT\": 33, \"I-AI INT\": 34, \"B-AI OUV\": 35, \"I-AI OUV\": 36, \"B-NCAD AI\": 37,\n",
    "    \"I-NCAD AI\": 38, \"B-NOUV AI\": 39, \"I-NOUV AI\": 40, \"B-AG\": 41, \"I-AG\": 42, \"B-AI\": 43, \"I-AI\": 44, \"B-ATOT\": 45, \"I-ATOT\": 46, \"B-ATOT CAD\": 47, \"I-ATOT CAD\": 48, \"B-ATOT INT\": 49,\n",
    "    \"I-ATOT INT\": 50, \"B-ATOT OUV\": 51, \"I-ATOT OUV\": 52, \"B-NCAD ATOT\": 53, \"I-NCAD ATOT\": 54, \"B-NOUV ATOT\": 55, \"I-NOUV ATOT\": 56, \"B-PPV\": 57, \"I-PPV\": 58, \"B-PPVm\": 59, \"I-PPVm\": 60\n",
    "}\n",
    "\n",
    "numeric_label_list =[label_to_numeric[label] for label in word_label_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"Jean-Baptiste/camembert-ner\"\n",
    "batch_size = 8\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(word_label_list), ignore_mismatched_sizes=True) #this last argument might be a mistake\n",
    "\n",
    "# import data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final data formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the data at the format we are interested in\n",
    "output_path_csv = r\"../data/processed/data449_tokens_labels.csv\"\n",
    "df, dataset = generate_data_format(data, full_dataframe=True, label_list=word_label_list, numeric_labels=label_to_numeric, save_to_csv=True, output_path_csv=output_path_csv)\n",
    "\n",
    "# We split the data into three subsets for the training\n",
    "train_data, test_data, val_data = split_dataset(dataset,random_seed=42)\n",
    "\n",
    "# turn them to dataset object\n",
    "train_dataset = turn_to_dataset(train_data)\n",
    "test_dataset = turn_to_dataset(test_data)\n",
    "val_dataset = turn_to_dataset(val_data)\n",
    "\n",
    "# We tokenize and align the labels of this sub-datasets\n",
    "tokenized_train = tokenize_and_align(train_dataset, label_all_tokens=True)\n",
    "tokenized_test = tokenize_and_align(test_dataset, label_all_tokens=True)\n",
    "tokenized_val = tokenize_and_align(val_dataset, label_all_tokens=True)\n",
    "\n",
    "# We turn them back to the dataset format as they were dictionnaries\n",
    "tokenized_train = turn_to_dataset(tokenized_train)\n",
    "tokenized_test = turn_to_dataset(tokenized_test)\n",
    "tokenized_val = turn_to_dataset(tokenized_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_train,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_test,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    tokenized_val,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training arguments\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "# We want to do a metrics function to compute the accuracy of the model\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    print(predictions,labels)\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [word_label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [word_label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    print(true_predictions,true_labels)\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    print(results)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## V1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "model_checkpoint = \"Jean-Baptiste/camembert-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\") #this last argument might be a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Empty the GPU cache memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# This will print the device (either 'cuda' or 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# You can then move your model and data to this device like this:\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the number of labels\n",
    "model.classifier=nn.Linear(in_features=768, out_features=31, bias=True)\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_conll(path:str):\n",
    "    # Initialize a list to store the data\n",
    "    conll_data = []\n",
    "\n",
    "    # Open the CoNLL file in read mode\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        conll_data = file.read()\n",
    "        # Read each line in the file\n",
    "\n",
    "    # Split the data into sentences\n",
    "    sentences = conll_data.strip().split('\\n\\n')\n",
    "\n",
    "    # Initialize empty lists to store text and labels\n",
    "    text_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Process each sentence\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split('\\n')\n",
    "        text = \" \".join(token.split()[0] for token in tokens)\n",
    "        labels = \" \".join(token.split()[-1] for token in tokens)\n",
    "        text_list.append(text)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame({'text': text_list, 'label': labels_list})\n",
    "\n",
    "    return df\n",
    "\n",
    "#we divide the data into train, test, and validation sets\n",
    "\n",
    "def split_data(data_dict, train_size=0.8, test_size=0.1, val_size=0.1, random_seed=None):\n",
    "    # Set a random seed for reproducibility\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Combine input_ids, attention_mask, and aligned_labels into a single list\n",
    "    combined_data = list(zip(data_dict['input_ids'], data_dict['attention_mask'], data_dict['labels']))\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.shuffle(combined_data)\n",
    "\n",
    "    # Calculate the sizes of each set\n",
    "    total_size = len(combined_data)\n",
    "    train_size = int(train_size * total_size)\n",
    "    test_size = int(test_size * total_size)\n",
    "    val_size = int(val_size * total_size)\n",
    "\n",
    "    # Split the data into train, test, and val sets\n",
    "    train_data = combined_data[:train_size]\n",
    "    test_data = combined_data[train_size:train_size + test_size]\n",
    "    val_data = combined_data[train_size + test_size:train_size + test_size + val_size]\n",
    "\n",
    "    # Unzip the data to restore the original structure\n",
    "    train_input_ids, train_attention_mask, train_aligned_labels = zip(*train_data)\n",
    "    test_input_ids, test_attention_mask, test_aligned_labels = zip(*test_data)\n",
    "    val_input_ids, val_attention_mask, val_aligned_labels = zip(*val_data)\n",
    "\n",
    "    # Create dictionaries for the train, test, and val sets\n",
    "    train_set = {\n",
    "        'input_ids': list(train_input_ids),\n",
    "        'attention_mask': list(train_attention_mask),\n",
    "        'labels': list(train_aligned_labels)\n",
    "    }\n",
    "    test_set = {\n",
    "        'input_ids': list(test_input_ids),\n",
    "        'attention_mask': list(test_attention_mask),\n",
    "        'labels': list(test_aligned_labels)\n",
    "    }\n",
    "    val_set = {\n",
    "        'input_ids': list(val_input_ids),\n",
    "        'attention_mask': list(val_attention_mask),\n",
    "        'labels': list(val_aligned_labels)\n",
    "    }\n",
    "\n",
    "    return train_set, test_set, val_set\n",
    "\n",
    "def turn_sentence_to_list(sentence):\n",
    "    \"\"\"\n",
    "    Turn a sentence into a list of words\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to tokenize\n",
    "\n",
    "    Returns:\n",
    "        list: list of words\n",
    "    \"\"\"\n",
    "    return sentence.split()\n",
    "\n",
    "def format_text(df):\n",
    "    formated_text = []\n",
    "\n",
    "    text = df[\"text\"]\n",
    "    for i in text:\n",
    "        i = turn_sentence_to_list(i)\n",
    "        formated_text.append(i)\n",
    "\n",
    "    # we add it to the dataframe\n",
    "    df[\"formated_text\"] = formated_text\n",
    "    return df\n",
    "\n",
    "def format_labels(df):\n",
    "    labels = df[\"label\"].tolist()\n",
    "\n",
    "    formated_labels = []\n",
    "\n",
    "    for label in labels:\n",
    "        # label = list_to_string(label)\n",
    "        label = turn_sentence_to_list(label)\n",
    "        formated_labels.append(label)\n",
    "        # print(label)\n",
    "\n",
    "    # we add it to the dataframe\n",
    "\n",
    "    df[\"formated_labels\"] = formated_labels\n",
    "    return df\n",
    "\n",
    "def change_ids(list_ids:list, new_id:dict):\n",
    "    \"\"\"\n",
    "    change the ids of a list of ids to a new id\n",
    "\n",
    "    Args:\n",
    "        list_ids (list): list of ids\n",
    "        new_id (dict): dictionary with the new id\n",
    "    \"\"\"\n",
    "    return [new_id.get(id) for id in list_ids]\n",
    "\n",
    "def align_labels(word_ids:list, tag_list:list):\n",
    "    \"\"\"\n",
    "    Align the labels with the words\n",
    "\n",
    "    Args:\n",
    "        word_ids (list): list of ids of the words\n",
    "        tag_list (list): list of tags\n",
    "    \"\"\"\n",
    "    aligned_labels = []\n",
    "    for i in word_ids:\n",
    "        if i is None:\n",
    "            aligned_labels.append(-100)\n",
    "        else:\n",
    "            aligned_labels.append(tag_list[i])\n",
    "    return aligned_labels\n",
    "\n",
    "def check_labels(list_labels:list):\n",
    "    for label in list_labels:\n",
    "        if type(label)!=int:\n",
    "            print(label)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def count_error(df, column:str):\n",
    "    \"\"\"\n",
    "    Count the number of errors - a cell containing a non numerical value - in a column of a dataframe\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): dataframe to check\n",
    "        column (str): column to check\n",
    "\n",
    "    Returns:\n",
    "        int: number of errors\n",
    "    \"\"\"\n",
    "    return len(df[column])- sum(df[column].apply(lambda x: check_labels(x)))\n",
    "\n",
    "def create_iids_am(df):\n",
    "    \"\"\"\n",
    "    Create the input ids and attention mask columns\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe containing the data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe containing the data with the input ids and attention mask columns\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for _,i in df.iterrows():\n",
    "        input = i[\"ids\"][\"input_ids\"]\n",
    "        attention = i[\"ids\"][\"attention_mask\"]\n",
    "\n",
    "        input_ids.append(input)\n",
    "        attention_mask.append(attention)\n",
    "\n",
    "    df[\"input_ids\"] = input_ids\n",
    "    df[\"attention_mask\"] = attention_mask\n",
    "    return df\n",
    "\n",
    "def select_columns(df, columns:list):\n",
    "    \"\"\"\n",
    "    Select columns from a dataframe\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe\n",
    "        columns (list): list of columns to select\n",
    "\n",
    "    \"\"\"\n",
    "    df = df[columns].copy()\n",
    "    return df\n",
    "\n",
    "def tokenize_and_align_data(path_conll:str, new_id:dict):\n",
    "    \"\"\"\n",
    "    Tokenize the text and align the labels\n",
    "\n",
    "    Args:\n",
    "        path_conll (str): path to the conll file\n",
    "        new_id (dict): dictionary with the new id\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe containing the data\n",
    "    \"\"\"\n",
    "    #charge and create the df\n",
    "    df = charge_conll(path_conll)\n",
    "    df = format_text(df)\n",
    "    df = format_labels(df)\n",
    "    df[\"new_labels\"]=df[\"label\"].apply(lambda x: change_ids(x.split(\" \"), new_id))\n",
    "\n",
    "    #tokenize and align the text\n",
    "    df[\"ids\"] = df[\"formated_text\"].apply(lambda x: tokenizer(x, truncation=True, is_split_into_words=True))\n",
    "    df = create_iids_am(df)\n",
    "    df[\"word_ids\"] = df[\"formated_text\"].apply(lambda x: tokenizer(x, truncation=True, is_split_into_words=True).word_ids())\n",
    "    df[\"aligned_labels\"] = df.apply(lambda x: align_labels(x[\"word_ids\"], x[\"new_labels\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "def apply_tokenization(conll_path:str, new_id:dict, columns:list, new_names:dict, save_path=False, output_save_csv=None):\n",
    "    \"\"\"\n",
    "    This function apply the tokenization and alignment to a conll file and select the columns we want to keep\n",
    "\n",
    "    Args:\n",
    "        conll_path (str): path to the conll file\n",
    "        new_id (dict): dictionary with the new id\n",
    "        columns (list): list of columns to keep\n",
    "        new_names (dict): dictionary with the new names of the columns\n",
    "        save_path (bool, optional): if True, save the dataframe in a csv file. Defaults to False.\n",
    "        output_save_csv ([type], optional): path to the csv file. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe containing the data\n",
    "    \"\"\"\n",
    "    df = tokenize_and_align_data(conll_path, new_id=new_id)\n",
    "    df = select_columns(df, columns)\n",
    "    df = df.rename(columns=new_names)\n",
    "    #we check the length of the two columns so that they are of the same dimensions\n",
    "    print(f\"nombre de 'aligned_labels' faux: {count_error(df, 'aligned_labels')}\")\n",
    "    if save_path:\n",
    "        df.to_csv(output_save_csv, index=False)\n",
    "    return df\n",
    "\n",
    "def final_formating(df, start:int, end:int):\n",
    "    \"\"\"\n",
    "    Collect the data from a dataframe in a list for a given range of sentences and store them into a dictionnary\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe containing the data\n",
    "        start (int): index of the first sentence to collect\n",
    "        end (int): index of the last sentence to collect\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionnary containing the data\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(start, end):\n",
    "        input_ids.append(df[\"input_ids\"][i])\n",
    "        attention_mask.append(df[\"attention_mask\"][i])\n",
    "        labels.append(df[\"aligned_labels\"][i])\n",
    "\n",
    "    data = {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n",
    "    return data\n",
    "\n",
    "def download_and_treat_data(conll_path:str, new_id:dict, columns:list, new_names:dict, start:int, end:int, csv=False, output_save=None):\n",
    "    \"\"\"\n",
    "    This function compile all the previous one and treat automatically all data provided as conll format.\\n\n",
    "    The objective is to provide a dictionnary containing the data for a given range of sentences with only one function. \\n\n",
    "    The same results can be obtained by parts with apply_tokenization and final_formating functions. This one is more a convenience function.\\n\n",
    "    It is also possible to obtain a csv file if csv is set to True and a path is provided in output_save.\n",
    "\n",
    "    Args:\n",
    "        conll_path (str): path to the conll file\n",
    "        new_id (dict): dictionnary to change the labels\n",
    "        columns (list): columns to keep\n",
    "        new_names (dict): new names of the columns\n",
    "        start (int): index of the first sentence to collect\n",
    "        end (int): index of the last sentence to collect\n",
    "    \n",
    "    Returns:\n",
    "        dict: dictionnary containing the data\n",
    "    \"\"\"\n",
    "    df = apply_tokenization(conll_path, new_id=new_id, columns=columns, new_names=new_names)\n",
    "\n",
    "    if csv:\n",
    "        df.to_csv(output_save, index=False)\n",
    "\n",
    "    data = final_formating(df, start, end)\n",
    "    return data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_id = {\"O\":0,\"B-SYND\":1, \"I-SYND\":2,  \"B-DIR\":3, \"I-DIR\":4, \"B-DATE\":5, \"I-DATE\":6, \"B-ENT\":7, \"I-ENT\":8, \"B-CAD\":9, \"I-CAD\":10,  \"B-INT\":11, \"I-INT\":12, \"B-OUV\":13, \"I-OUV\":14 , \"B-NCAD\":15, \"I-NCAD\":16 ,\"B-NOUV\":17, \"I-NOUV\":18, \"B-TOUS\":19,\"I-TOUS\":20, \"B-AG CAD\":21,\"I-AG CAD\":22, \"B-AG INT\":23, \"I-AG INT\":24, \"B-AG OUV\":25, \"I-AG OUV\":26,\"B-AG NCAD\":27, \"I-AG NCAD\":28, \"B-AG NOUV\":29, \"I-AG NOUV\":30,\"B-AI CAD\":31, \"I-AI CAD\":32,\"B-AI INT\":33, \"I-AI INT\":34,\"B-AI OUV\":35, \"I-AI OUV\":36,\"B-AI NCAD\":37, \"I-AI NCAD\":38,\"B-AI NOUV\":39, \"I-AI NOUV\":40, \"B-AG\":41, \"I-AG\":42,\"B-AI\":43, \"I-AI\":44,\"B-ATOT\":45,\"I-ATOT\":46,\"B-ATOT CAD\":47, \"I-ATOT CAD\":48,\"B-ATOT INT\":49, \"I-ATOT INT\":50,\"B-ATOT OUV\":51, \"I-ATOT OUV\":52, \"ATOT OUV\":53,\"B-ATOT NCAD\":54, \"I-ATOT NCAD\":55, \"B-ATOT NOUV\":56, \"I-ATOT NOUV\":57,\"B-PPV\":58, \"I-PPV\":59,\"B-PPVm\":60, \"I-PPVm\":61}\n",
    "new_id = {\"O\":0,\"B-SYND\":1, \"I-SYND\":1, \"SYND\":1, \"B-DIR\":2, \"I-DIR\":2, \"DIR\":2, \"B-DATE\":4, \"I-DATE\":4, \"DATE\":4, \"B-ENT\":3, \"I-ENT\":3, \"ENT\":3, \"B-CAD\":5, \"I-CAD\":5, \"CAD\":5, \"B-INT\":6, \"I-INT\":6, \"INT\":6,\"B-OUV\":7, \"I-OUV\":7, \"OUV\":7, \"B-NCAD\":8, \"I-NCAD\":8, \"NCAD\":8,\"B-NOUV\":9, \"I-NOUV\":9, \"NOUV\":9, \"B-TOUS\":10,\"I-TOUS\":10, \"TOUS\":10, \"B-AG CAD\":11,\"I-AG CAD\":11, \"AG CAD\":11, \"B-AG INT\":12, \"I-AG INT\":12, \"AG INT\":12, \"B-AG OUV\":13, \"I-AG OUV\":13, \"AG OUV\":13,\"B-AG NCAD\":14, \"I-AG NCAD\":14, \"AG NCAD\":14, \"B-AG NOUV\":15, \"I-AG NOUV\":15, \"AG NOUV\":15,\"B-AI CAD\":16, \"I-AI CAD\":16,\"AI CAD\":16,\"B-AI INT\":17, \"I-AI INT\":17, \"AI INT\":17,\"B-AI OUV\":18, \"I-AI OUV\":18,\"AI OUV\":18,\"B-AI NCAD\":19, \"I-AI NCAD\":19,\"AI NCAD\":19,\"B-AI NOUV\":20, \"I-AI NOUV\":20, \"AI NOUV\":20, \"B-AG\":21, \"I-AG\":21, \"AG\":21,\"B-AI\":22, \"I-AI\":22,\"AI\":22,\"B-ATOT\":23,\"I-ATOT\":23, \"ATOT\":23,\"B-ATOT CAD\":24, \"I-ATOT CAD\":24, \"ATOT CAD\":24,\"B-ATOT INT\":25, \"I-ATOT INT\":25,\"ATOT INT\":25,\"B-ATOT OUV\":26, \"I-ATOT OUV\":26, \"ATOT OUV\":26,\"B-ATOT NCAD\":27, \"I-ATOT NCAD\":27, \"ATOT NCAD\":27,\"B-ATOT NOUV\":28, \"I-ATOT NOUV\":28, \"ATOT NOUV\":28,\"B-PPV\":29, \"I-PPV\":29, \"PPV\":29,\"B-PPVm\":30, \"I-PPVm\":30, \"PPVm\":30}\n",
    "columns = [\"formated_text\", \"formated_labels\",\"new_labels\",\"word_ids\", \"input_ids\", \"attention_mask\", \"aligned_labels\"]\n",
    "new_names = {\"formated_text\": \"text\", \"new_labels\": \"label\", \"word_ids\": \"word_ids\", \"aligned_labels\": \"aligned_labels\"}\n",
    "conll_path = r\"../data/raw/data449.conll\"\n",
    "start = 0\n",
    "end = 449\n",
    "output_save = r\"../data/intermediate/data449_token.csv\"\n",
    "\n",
    "data, df_final = download_and_treat_data(conll_path=conll_path, new_id=new_id, columns=columns, new_names=new_names, start=start, end=end, csv=True, output_save=output_save)\n",
    "\n",
    "train_data, test_data, val_data = split_data(data)\n",
    "\n",
    "# Create a Dataset object\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "# Create a list of labels\n",
    "reverse_id = {v: k for k, v in new_id.items()}\n",
    "second_elements = [value for value in reverse_id.values()]\n",
    "label_list = second_elements\n",
    "print(label_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"Jean-Baptiste/camembert-ner\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list), ignore_mismatched_sizes=True) #this last argument might be a mistake\n",
    "\n",
    "# import data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors='pt')\n",
    "\n",
    "# Dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))[\"input_ids\"].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# training arguments\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "# metric used for evaluation\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "# We want to do a metrics function to compute the accuracy of the model\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    print(predictions,labels)\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    print(true_predictions,true_labels)\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    print(results)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
